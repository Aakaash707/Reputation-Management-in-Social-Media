{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64a16d7-b1d4-467e-9e72-f5a97abad3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "from PIL import Image\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import easyocr\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e31f2d-4804-4d2e-aaae-36bda73454f7",
   "metadata": {},
   "source": [
    "## Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5c8795-4638-48c9-8fb4-eea8bdccfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db4da71-5963-4ef4-978f-56122b61327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    all_reviews=list()\n",
    "    for text in df:\n",
    "        text = text.lower()\n",
    "        text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "        text = \" \".join([c for c in text.split() if c not in stop_words and c.isalpha()])\n",
    "        all_reviews.append(text)\n",
    "    all_text = \" \".join(all_reviews)\n",
    "    all_words = all_text.split()\n",
    "    return all_reviews, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f668391a-d18a-467c-8e6c-860c3b0416b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(words):\n",
    "    from collections import Counter \n",
    "    # Count all the words using Counter Method\n",
    "    count_words = Counter(words)\n",
    "    total_words=len(words)\n",
    "    sorted_words=count_words.most_common(total_words)\n",
    "    print(\"Top ten occuring words : \",sorted_words[:10])\n",
    "\n",
    "    vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}\n",
    "    print(len(vocab_to_int))\n",
    "\n",
    "    return vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8bd4ed-e6fa-4c9d-9be1-f9db688f63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(reviews, vocab):\n",
    "    encoded_reviews=list()\n",
    "    for review in reviews:\n",
    "      encoded_review=list()\n",
    "      for word in review.split():\n",
    "        if word not in vocab.keys():\n",
    "          #if word is not available in vocab_to_int put 0 in that place\n",
    "          encoded_review.append(0)\n",
    "        else:\n",
    "          encoded_review.append(vocab[word])\n",
    "      encoded_reviews.append(encoded_review)\n",
    "    return encoded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc971f2-ef27-462b-ab60-079b06c13493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(encoded_reviews):\n",
    "    sequence_length=150\n",
    "    features=np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
    "    for i, review in enumerate(encoded_reviews):\n",
    "        review_len=len(review)\n",
    "        if (review_len<=sequence_length):\n",
    "            zeros=list(np.zeros(sequence_length-review_len))\n",
    "            new=zeros+review\n",
    "        else:\n",
    "            new=review[:sequence_length]\n",
    "        features[i,:]=np.array(new)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1a62b2-2c03-4d68-b5ad-1c08ca8a910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten occuring words :  [('place', 218664), ('food', 214831), ('good', 202116), ('like', 177057), ('get', 161923), ('one', 157546), ('would', 146896), ('time', 144596), ('service', 139934), ('great', 134896)]\n",
      "517775\n"
     ]
    }
   ],
   "source": [
    "with codecs.open('/Users/aakaash_kb/Developer/Final Project/Dataset/yelp_review_full_csv/train.csv', 'r', encoding='ISO-8859-1') as f:\n",
    "    df_train = pd.read_csv(f)\n",
    "\n",
    "df_train.columns = [\"Label\", \"Text\"]\n",
    "df_train = df_train.loc[df_train.Label.isin([1, 3, 5])]\n",
    "df = df_train.Text.tolist()\n",
    "\n",
    "reviews, words = pre_process(df)\n",
    "vocab = create_vocab(words)\n",
    "vocab = dict(list(vocab.items())[:20000])\n",
    "with codecs.open('/Users/aakaash_kb/Developer/Final Project/demo/reviews.csv', 'r', encoding='ISO-8859-1') as f:\n",
    "    df_test = pd.read_csv(f)\n",
    "\n",
    "df_test = df_test[\"reviews\"][:50].tolist()\n",
    "\n",
    "test_encode = encode_features(df_test, vocab)\n",
    "test_features = pad_features(test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3150eb3-b501-428e-b26b-f773ba0d6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM0(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers):    \n",
    "        super().__init__()\n",
    "        self.output_size=output_size\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        #Embedding and LSTM layers\n",
    "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        #Linear and sigmoid layer\n",
    "        self.fc1=nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size=x.size()\n",
    "        \n",
    "        #Embedding and LSTM output\n",
    "        x = x.long()\n",
    "        embedd=self.embedding(x)\n",
    "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
    "        \n",
    "        #stack up the lstm output\n",
    "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        #dropout and fully connected layers\n",
    "        out=self.fc1(lstm_out)\n",
    "        soft_out = out.reshape(list(batch_size)+[3])\n",
    "        soft_out = soft_out[:, -1, :]\n",
    "        return soft_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        \"\"\"Initialize Hidden STATE\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157ad9e8-8902-4a33-80d6-b1ce3113a765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM0(\n",
      "  (embedding): Embedding(20001, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True)\n",
      "  (fc1): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "vocab_size = 20000+1 # +1 for the 0 padding\n",
    "output_size = 3\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "model = LSTM0(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0fa241-eb18-4bb5-a461-02c42a6fdfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/Users/aakaash_kb/Developer/Final Project/demo/updated_model/lstm_04.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980bbbff-46eb-4720-82f3-92b7e1a91cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 0 0 0 2 2 2 0 2 0 2 2 2 2 2 2 1 2 0 0 2 2 2 0 2 2 2 1 2 2 2 2 1 1 2\n",
      " 2 2 2 0 2 2 0 2 2 2 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "inp_features = torch.FloatTensor(test_features)\n",
    "model.eval()\n",
    "device=\"cpu\"\n",
    "batch_size = 50\n",
    "h = model.init_hidden(batch_size, device)\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "with torch.inference_mode():\n",
    "    h = tuple([each.data for each in h])\n",
    "    pred, h = model(inp_features, h)\n",
    "    res = sm(pred).argmax(dim=1).numpy()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f48f712-bb3b-4d4e-8fec-f95db1005f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative Response': 11, 'Neutral Response': 6, 'Positive Response': 33}\n"
     ]
    }
   ],
   "source": [
    "text_op = {\"Negative Response\":0,\"Neutral Response\":0,\"Positive Response\":0}\n",
    "for i in list(res):\n",
    "    if i == 0:\n",
    "        text_op[\"Negative Response\"] += 1\n",
    "    elif i == 1:\n",
    "        text_op[\"Neutral Response\"] += 1\n",
    "    else:\n",
    "        text_op[\"Positive Response\"] += 1\n",
    "print(text_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d9602-d1df-4664-95f5-72b3ae0e3f8f",
   "metadata": {},
   "source": [
    "## Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07b3b50-9068-4667-8f33-69cb86404170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)  # Read the entire audio file\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae9d372d-7cd8-4531-8bf0-19364c91dab1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/16.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/17.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/15.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/29.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/sgdfhasgfdhgasf.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/28.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/14.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/1714922670028ofscl0o4-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/17149228163560yuy9pej-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/10.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/11.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/1714922693198r57hc04-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/13.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/12.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/17149228661582sp902q-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/1714922543186a4qtauvi-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/9.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/8.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/17149226474335blo08vo-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/6.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/7.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/1714922622901ycz75ut-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/1714922726002fk3le1e-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/5.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/4.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/0.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/1.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/3.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/2.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/17149227521871vcsvi8g-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/23.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/37.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/1714922790847tptygy6xa-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/36.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/22.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/34.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/20.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/21.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/35.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/19.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/31.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/25.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/17149229300656ewm5c0e-voicemaker.in-speech.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/24.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/30.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/18.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/26.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/32.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/33.wav\n",
      "/Users/aakaash_kb/Developer/Final Project/demo/audio data/27.wav\n",
      "['before some months this maggi noodles suffers goes from doubtful situations and there was many kinds of fake news goes viral for close this noodles product and researchers done many kinds of research maggi noodles but no issue is found in maggi and again Maggi games in market with its delicious flower and test', 'the flavours are so perfectly blended that in each bite the flavour come so nicely the packaging of the product is also good it comes in a Yellow packet which is very much appealing', 'maggi is my most loved noodle there are such a large number of new brands in the market however maggies masala is so one of a kind and more delicious than some other brand', \"according to me maggi is not good for health so please don't eat it\", \"if you go through the ingredients you can find that it's made up from refined flour maida which is not easily digested it also contains preservatives which is also not good for our health please take a look and then serve after all we first care for our dear one\", 'which on one time the Maggi market was over due to using something which is very harmful to health but what happens again it runs in a Indian market maggi noodles is very good in taste but you eat Maggi noodles you will fill a sleep', 'maggi noodles are most love noodles by every generation of people especially by the younger generation there are so many brands available in the market for the noodles but still people go for Maggi noodles', 'maggi noodles is a type of food which is easy to prepare and tasty also but it contains chemical which is effective for Healthcare we can take more and sometimes I used to give it up to 5 packet but I can take out the daily so I think it', \"I get always accepted for Maggi noodles maggi is on the top of the noodles because of its wonderful test as well as easy way to cook in few minutes it's available in small packing and also in Big packing I always perform Maggi noodles\", \"the maggi noodles is the Gateway of diseases in our body there is a pack of spices in the maggi noodles pack we didn't know that how much this is old\", 'I have eat Maggi daily for breakfast and whenever I feeling hungry maggi is comes with very tasty and yummy flavour', \"hi the servant from Bangalore I brought new Maggi Masala product today and it is very bad which contains a better like cockroach I really hate this product and it's not good for health I started vomiting\", \"if we talk about its flavour which is generally amazing and delicious in taste all of the ingredients are blended so finally that it's small packet of masala contain almost all of ingredients with fine characterization\", 'maggi noodles which is the most tasteless noodles ever eaten by me I am beating this noodles from my childhood and thought that these are the original and last noodles', 'the taste is so yummy and all people have different age groups love Maggi noodles that I loved it is noodles and I would definitely recommend this to others as well', 'in this time Maggi has become two famous for as taste and flavour but unfortunately this is not healthy for all people and mainly for the kids', 'as soon as I think to eat noodle I definitely choose maggi is it is best in taste and its flavour is amazing maggi is one of the best noodles ever an fmd also its flavours are not matched by any other noodles', 'it is because the news released by food research department that it contains the materials as preservatives which were used in the gunpowder and it was totally unfair treatment of love of people for Maggi and after that I gave up eating noodles and you should to give it up', \"whenever I heard the word Maggi my stomach starts crying I love Maggi more than any other food item and of course it's a life saver for everyone because whenever my mum goes somewhere far and I have nothing to eat Maggi always saves me from hunger\", 'I really love Maggi because I love the taste and Aroma of the Maggi nothing is better than Maggi for me the taste of maggi is super cool I just want to taste the spicy Maggi but till now I am in love with Maggi the colour and Packaging of maggi is so attractive', 'when it was banned in market due to some reasons of quality some fan of Maggi were getting disappointed but goodness is that it comes again and drop the position and reputation again', 'at the end I would like to say the maggi noodles are really tasty and very easy to make but it should be have a limit to all the people and mainly the kids', 'I love Maggi noodles it is so good and it is so easy to cook it takes only around 2 minutes to cook Maggi is the only thing that can give me happiness and only two minutes after the stress of the whole day who likes to cook a long meal for alone', 'I thought maggi is healthy and for that reason only I used to eat Maggi for Once in 3 days with my family doctor told me about side effects of Maggi', \"doctor told me if a person eat Maggi noodles continuously the weekend suffer from hypertension diabetes high cholesterol obesity etc it also increase fat in our body when I started to avoid maggi noodles from my sister so friends I think maggi noodles specially affect no children health try to avoid it as much as possible that's my opinion\", 'I have eaten this product that is Maggi noodles and it is one of my favourite among all the other noodles in the market', 'maggi is the best brand of noodles and pasta it is very easy to cook no other ingredients need to cook it I always eat Maggi in the evening because I have a little time to cook so I only prefer noodles my nephew also easy Maggi even he take it in his tiffin box', \"I tell you maggi noodles is not good for health it's easy to cook that's why some people cook Maggi noodles I cooked maggi noodles many time but when I eat Maggi noodles I feel like vomiting and I can't eat more\", 'maggi noodles is one of the most popular noodles brand and also its taste is also good but due to some circumstances people think it is injurious to health but it is not true because no one dies by eating this', 'are used to be Maggi lover but after the problems cause last year they have did much compromises with the quality of the product and masala they provide is not enough for the packet', 'we are all deserve for good quality maggi is not so good for our health', 'it is very good tasty noodles till now I eat it I am eating it from childhood it can be made within 5 minutes and it is very good in taste and flavour is also good', 'MSG is used in maggi it is very bad for health MSG is known to cause no logical problems headaches and inflammation in the liver it also increases your risk for metabolic syndrome and lower your appetite', 'the masala taste is very unique although a lot of flavours are available in maggi it has passed all the test if health and hygiene', \"at present this moment going to past approx 15 years ago first time I saw the Maggi and after each I feel very well because it taste too good and its masala a very attractive to People's judge that s y peoples love the Maggi but but it's not good for our health because it's one of the jump type of fast food\", 'due to ban on Maggi there are lots of other noodle company launched the noodles and promote it is it is more healthier than that of Maggi but Maggi again comes to the market and by failing The Other brands again dominating in a noodles category', 'after a controversy about using harmful ingredients it is not totally safe and no harmful ingredients are used now', 'the taken by it to be processed is the lowest in case of foods that are processed in fire so it helps mothers in preparing a delicious food in no time', 'good treat for taste buds', \"the bundling has been the same throughout the years yet the yellow parcel is so engaging in appealing the cost is presently raised 5 parcel is little and now however that won't make it less more delicious\", 'maggi noodles is not good food for human health this is normal flavour and normal tasty noodles', 'even if your mummy is not there to help you you can cook it by yourself with few easy steps in it will be cooked in just 2 minutes the taste is so amazing', 'sometime ago such elements were found in with cancer for this reason I leave Maggi but when everything was found to be right in it then I started eating again maggi is my favourite noodles', 'I like it taste and during my college time I used to get up late so I cooked Maggi and my hunger and it has been a part of my life', \"it causes restless sleep every single time the next time you can't sleep well think about if you had some instant noodles\", 'I adore the enchantment masala enhance each of my most loved and the new hot heads enhance they presented is w g a t I require I am a significant other of anything zesty and hot heads brilliant Hans is the best', 'approx 2 years ago it had banned by the fssai and reason behind was that it did not meet hey required quality which is set by fssai but after some months Maggi came back with the maintain standard of quality and liked by its flowers same as before due to its yummy and amazing taste which could not be beaten by any noodles', 'this price is high and quality is low I abandoned to using Maggi noodles', 'maggi is the most popular fast food now it is ready in just 5 minutes it is a very delicious Stephen for every child every mother chooses Maggi for tiffin', 'maggi is a good quality product and its taste is very delicious dot it has many flavours like chicken chilli etc']\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing audio files\n",
    "directory_path = \"/Users/aakaash_kb/Developer/Final Project/demo/audio data\"\n",
    "\n",
    "audio_semantics = []\n",
    "\n",
    "audio_extensions = [\".mp3\", \".wav\", \".ogg\", \".flac\"]  \n",
    "for filename in os.listdir(directory_path):\n",
    "    if any(filename.endswith(ext) for ext in audio_extensions):\n",
    "        full_path = os.path.join(directory_path, filename)\n",
    "        print(full_path)\n",
    "        semantic = convert_audio_to_text(full_path)\n",
    "        audio_semantics.append(semantic)\n",
    "\n",
    "print(audio_semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54d9860a-0aa5-4968-b146-2bea4fed5377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0989c6c5-84fc-4047-839d-243b25d4d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_encode = encode_features(audio_semantics, vocab)\n",
    "audio_features = pad_features(audio_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f18a713-d9df-4ebd-b394-411ca9240fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 0 0 1 1 1 2 1 1 0 1 0 2 1 2 2 2 2 0 1 2 0 0 2 1 0 1 0 0 1 2 1 1 1 2\n",
      " 2 2 1 1 2 2 2 1 2 2 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "inp_features = torch.FloatTensor(audio_features)\n",
    "model.eval()\n",
    "device=\"cpu\"\n",
    "batch_size = 50\n",
    "h = model.init_hidden(batch_size, device)\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "with torch.inference_mode():\n",
    "    h = tuple([each.data for each in h])\n",
    "    pred, h = model(inp_features, h)\n",
    "    ares = sm(pred).argmax(dim=1).numpy()\n",
    "    print(ares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b7628e4-9592-49fa-bf1d-5f4b9308959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative Response': 11, 'Neutral Response': 18, 'Positive Response': 21}\n"
     ]
    }
   ],
   "source": [
    "audio_op = {\"Negative Response\":0,\"Neutral Response\":0,\"Positive Response\":0}\n",
    "for i in list(ares):\n",
    "    if i == 0:\n",
    "        audio_op[\"Negative Response\"] += 1\n",
    "    elif i == 1:\n",
    "        audio_op[\"Neutral Response\"] += 1\n",
    "    else:\n",
    "        audio_op[\"Positive Response\"] += 1\n",
    "print(audio_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42180d0e-43d7-41a1-bad1-02067ff44731",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ceec87c-f1c9-4fce-82dd-93542c7f4320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/Users/aakaash_kb/Developer/Final Project/caption_model\"\n",
    "caption_model = VisionEncoderDecoderModel.from_pretrained(model_dir)\n",
    "cfeature_extractor = ViTFeatureExtractor.from_pretrained(model_dir)\n",
    "ctokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "caption_model.to(device)\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10ad710e-0386-4b12-bcdf-4165ec39b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_step(image_paths):\n",
    "  images = []\n",
    "  for image_path in image_paths:\n",
    "    i_image = Image.open(image_path)\n",
    "    if i_image.mode != \"RGB\":\n",
    "      i_image = i_image.convert(mode=\"RGB\")\n",
    "\n",
    "    images.append(i_image)\n",
    "\n",
    "  pixel_values = cfeature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "  pixel_values = pixel_values.to(device)\n",
    "\n",
    "  output_ids = caption_model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "  preds = ctokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "  preds = [pred.strip() for pred in preds]\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1af6902a-7d2f-4837-8b06-d41a7de34c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"/Users/aakaash_kb/Developer/Final Project/demo/image data\"\n",
    "\n",
    "img_paths = []\n",
    "ocrs = []\n",
    "img_extensions = [\".jpeg\", \".jpg\", \".png\"]  \n",
    "for filename in os.listdir(directory_path):\n",
    "    if any(filename.endswith(ext) for ext in img_extensions):\n",
    "        full_path = os.path.join(directory_path, filename)\n",
    "        reader = easyocr.Reader(['en'])\n",
    "        result = reader.readtext(full_path)\n",
    "        if len(result) != 0:\n",
    "            ocrs.append(result[0][1])\n",
    "        else:\n",
    "            ocrs.append(\"\")\n",
    "        img_paths.append(full_path)\n",
    "captions = predict_step(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a774509-0638-4491-9f17-eb3191dd00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_semantics = []\n",
    "for i in range(len(captions)):\n",
    "    iop = captions[i] + \". \" + ocrs[i]\n",
    "    image_semantics.append(iop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9082018-f4f0-4302-9acb-6c8e7ee9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encode = encode_features(image_semantics, vocab)\n",
    "image_features = pad_features(image_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2a316bf-a3ed-4e1f-b582-6cb647037457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 1 1 2 2 2 1 0 2 2 2 2 0 0 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 2 2 2 2 0\n",
      " 2 2 1 0 2 0 2 0 1 0 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "inp_features = torch.FloatTensor(image_features)\n",
    "model.eval()\n",
    "device=\"cpu\"\n",
    "batch_size = 50\n",
    "h = model.init_hidden(batch_size, device)\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "with torch.inference_mode():\n",
    "    h = tuple([each.data for each in h])\n",
    "    pred, h = model(inp_features, h)\n",
    "    ires = sm(pred).argmax(dim=1).numpy()\n",
    "    print(ires)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8fd1868-1b6d-4b32-8a87-988381f83929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative Response': 20, 'Neutral Response': 7, 'Positive Response': 23}\n"
     ]
    }
   ],
   "source": [
    "image_op = {\"Negative Response\":0,\"Neutral Response\":0,\"Positive Response\":0}\n",
    "for i in list(ires):\n",
    "    if i == 0:\n",
    "        image_op[\"Negative Response\"] += 1\n",
    "    elif i == 1:\n",
    "        image_op[\"Neutral Response\"] += 1\n",
    "    else:\n",
    "        image_op[\"Positive Response\"] += 1\n",
    "print(image_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa04b60b-4d6e-4378-9ea8-1dd7e6b8382f",
   "metadata": {},
   "source": [
    "## Ensembled Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a28c55c5-a35d-4469-8fe6-16f2bf8192cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dict(dictionary):\n",
    "    total = sum(dictionary.values())\n",
    "    normalized_dict = {key: value / total for key, value in dictionary.items()}\n",
    "    return normalized_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecd69df1-9f63-473a-b80e-c00089250e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_dicts(text_op, audio_op, image_op, ratios):\n",
    "    normalized_dict_text = normalize_dict(text_op)\n",
    "    normalized_dict_audio = normalize_dict(audio_op)\n",
    "    normalized_dict_image = normalize_dict(image_op)\n",
    "    \n",
    "    weighted_dict_text = {key: normalized_dict_text[key] * ratios[0] for key in normalized_dict_text}\n",
    "    weighted_dict_audio = {key: normalized_dict_audio[key] * ratios[1] for key in normalized_dict_audio}\n",
    "    weighted_dict_image = {key: normalized_dict_image[key] * ratios[2] for key in normalized_dict_image}\n",
    "    \n",
    "    ensemble_output = {}\n",
    "    for key in weighted_dict_text:\n",
    "        ensemble_output[key] = weighted_dict_text[key] + weighted_dict_audio[key] + weighted_dict_image[key]\n",
    "    \n",
    "    total_sum = sum(ensemble_output.values())\n",
    "    ensemble_output_percentage = {key: round((value / total_sum) * 100, 2) for key, value in ensemble_output.items()}\n",
    "    \n",
    "    return ensemble_output_percentage\n",
    "\n",
    "ratios = [3, 1, 2]\n",
    "\n",
    "ensemble_op = ensemble_dicts(text_op, audio_op, image_op, ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e58038b3-9bfc-4658-8ba9-45308e4c5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repr(d):\n",
    "    for i in d:\n",
    "        print(i+\" : \"+str(d[i])+\"%\", end=\"  |  \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06ffb04c-21aa-40d9-9aa5-8b78abaa79f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Textual Data Summary:\n",
      "Negative Response : 11%  |  Neutral Response : 6%  |  Positive Response : 33%  |  \n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Audio Data Summary:\n",
      "Negative Response : 11%  |  Neutral Response : 18%  |  Positive Response : 21%  |  \n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Image Data Summary:\n",
      "Negative Response : 20%  |  Neutral Response : 7%  |  Positive Response : 23%  |  \n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Final Report:\n",
      "Negative Response : 28.0%  |  Neutral Response : 16.67%  |  Positive Response : 55.33%  |  \n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*90)\n",
    "print(\"\\nTextual Data Summary:\")\n",
    "repr(text_op)\n",
    "print(\"-\"*90)\n",
    "print(\"\\nAudio Data Summary:\")\n",
    "repr(audio_op)\n",
    "print(\"-\"*90)\n",
    "print(\"\\nImage Data Summary:\")\n",
    "repr(image_op)\n",
    "print(\"-\"*90)\n",
    "print(\"\\nFinal Report:\")\n",
    "repr(ensemble_op)\n",
    "print(\"-\"*90)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
